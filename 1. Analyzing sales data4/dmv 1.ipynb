{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3QRWD6oqUpK"
      },
      "outputs": [],
      "source": [
        "# Install necessary package\n",
        "!pip install openpyxl\n",
        "\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "# Upload files\n",
        "print(\"Please upload your sales data files (CSV, Excel, JSON):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "# Automatically detect uploaded files by extension\n",
        "csv_file = None\n",
        "excel_file = None\n",
        "json_file = None\n",
        "\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.csv'):\n",
        "        csv_file = filename\n",
        "    elif filename.endswith(('.xls', '.xlsx')):\n",
        "        excel_file = filename\n",
        "    elif filename.endswith('.json'):\n",
        "        json_file = filename\n",
        "\n",
        "\n",
        "print(f\"CSV file detected: {csv_file}\")\n",
        "print(f\"Excel file detected: {excel_file}\")\n",
        "print(f\"JSON file detected: {json_file}\")\n",
        "\n",
        "\n",
        "# Load files into DataFrames\n",
        "df_csv = pd.read_csv(csv_file, encoding='latin1') if csv_file else pd.DataFrame()\n",
        "df_excel = pd.read_excel(excel_file) if excel_file else pd.DataFrame()\n",
        "df_json = pd.read_json(json_file) if json_file else pd.DataFrame()\n",
        "\n",
        "\n",
        "# Function to explore data\n",
        "def explore_data(df, name='DataFrame'):\n",
        "    print(f\"\\n--- {name} info ---\")\n",
        "    print(df.info())\n",
        "    print(f\"\\n--- {name} head ---\")\n",
        "    print(df.head())\n",
        "    print(f\"\\n--- {name} missing values ---\")\n",
        "    print(df.isnull().sum())\n",
        "    print(f\"\\n--- {name} duplicates --- {df.duplicated().sum()}\")\n",
        "\n",
        "\n",
        "# Explore all datasets\n",
        "if not df_csv.empty: explore_data(df_csv, 'CSV Data')\n",
        "if not df_excel.empty: explore_data(df_excel, 'Excel Data')\n",
        "if not df_json.empty: explore_data(df_json, 'JSON Data')\n",
        "\n",
        "\n",
        "# Function to clean data\n",
        "def clean_data(df):\n",
        "    if df.empty:\n",
        "        return df\n",
        "    # Drop duplicates\n",
        "    df = df.drop_duplicates().copy()\n",
        "\n",
        "    # Fill missing numeric with 0, categorical with mode\n",
        "    for col in df.columns:\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            df[col] = df[col].fillna(0)\n",
        "        else:\n",
        "            if not df[col].mode().empty:\n",
        "                df[col] = df[col].fillna(df[col].mode()[0])\n",
        "            else:\n",
        "                df[col] = df[col].fillna('Unknown')\n",
        "    return df\n",
        "\n",
        "\n",
        "# Clean all datasets\n",
        "df_csv_clean = clean_data(df_csv)\n",
        "df_excel_clean = clean_data(df_excel)\n",
        "df_json_clean = clean_data(df_json)\n",
        "\n",
        "\n",
        "# Unify columns before concatenation\n",
        "# Find all columns used across datasets\n",
        "all_cols = set(df_csv_clean.columns).union(set(df_excel_clean.columns)).union(set(df_json_clean.columns))\n",
        "\n",
        "\n",
        "# Make sure all DataFrames have all columns\n",
        "def align_columns(df, all_cols):\n",
        "    for col in all_cols:\n",
        "        if col not in df.columns:\n",
        "            df[col] = np.nan  # fill missing columns with NaN\n",
        "    return df[sorted(all_cols)]\n",
        "\n",
        "\n",
        "df_csv_aligned = align_columns(df_csv_clean, all_cols)\n",
        "df_excel_aligned = align_columns(df_excel_clean, all_cols)\n",
        "df_json_aligned = align_columns(df_json_clean, all_cols)\n",
        "\n",
        "\n",
        "# Concatenate all data\n",
        "df_all = pd.concat([df_csv_aligned, df_excel_aligned, df_json_aligned], ignore_index=True)\n",
        "\n",
        "\n",
        "print(\"\\n--- Combined DataFrame info ---\")\n",
        "print(df_all.info())\n",
        "\n",
        "\n",
        "# Example data transformation: create 'Total_Sales' if 'Quantity' and 'Price' exist\n",
        "if 'Quantity' in df_all.columns and 'Price' in df_all.columns:\n",
        "    df_all['Total_Sales'] = df_all['Quantity'].astype(float) * df_all['Price'].astype(float)\n",
        "else:\n",
        "    print(\"Columns 'Quantity' and/or 'Price' missing, skipping 'Total_Sales' calculation.\")\n",
        "\n",
        "\n",
        "# Example descriptive statistics\n",
        "print(\"\\n--- Descriptive Statistics ---\")\n",
        "if 'Total_Sales' in df_all.columns:\n",
        "    total_sales = df_all['Total_Sales'].sum()\n",
        "    print(f\"Total Sales: {total_sales}\")\n",
        "\n",
        "\n",
        "if 'OrderID' in df_all.columns and 'Total_Sales' in df_all.columns:\n",
        "    avg_order_value = df_all.groupby('OrderID')['Total_Sales'].sum().mean()\n",
        "    print(f\"Average Order Value: {avg_order_value}\")\n",
        "\n",
        "\n",
        "if 'Product_Category' in df_all.columns:\n",
        "    print(\"\\nProduct Category Distribution:\")\n",
        "    print(df_all['Product_Category'].value_counts())\n",
        "\n",
        "\n",
        "# Visualizations\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "\n",
        "# Total Sales by Product Category (bar plot)\n",
        "if 'Product_Category' in df_all.columns and 'Total_Sales' in df_all.columns:\n",
        "    plt.figure(figsize=(10,6))\n",
        "    sns.barplot(data=df_all, x='Product_Category', y='Total_Sales', estimator=sum, ci=None)\n",
        "    plt.title('Total Sales by Product Category')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Pie chart of Product Category distribution\n",
        "if 'Product_Category' in df_all.columns:\n",
        "    plt.figure(figsize=(6,6))\n",
        "    df_all['Product_Category'].value_counts().plot.pie(autopct='%1.1f%%')\n",
        "    plt.title('Product Category Distribution')\n",
        "    plt.ylabel('')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Boxplot of Total Sales\n",
        "if 'Total_Sales' in df_all.columns:\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.boxplot(x=df_all['Total_Sales'])\n",
        "    plt.title('Distribution of Total Sales')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nAnalysis complete!\")\n"
      ]
    }
  ]
}